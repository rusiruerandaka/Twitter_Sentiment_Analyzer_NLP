{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6382,"status":"ok","timestamp":1733996093097,"user":{"displayName":"Erandaka Rusiru","userId":"04457590709685097582"},"user_tz":-330},"id":"xf7rjfpkMQgz","outputId":"62bfb555-9def-4268-817e-2f98c74ad31d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"]}],"source":["!pip install tensorflow\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23192,"status":"ok","timestamp":1733996492301,"user":{"displayName":"Erandaka Rusiru","userId":"04457590709685097582"},"user_tz":-330},"id":"Ezj7BdqFMbai","outputId":"3c3088d8-a7cd-4f67-e32c-5e669041507d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 330ms/step - accuracy: 0.7679 - loss: 0.6788 - val_accuracy: 0.9070 - val_loss: 0.5843\n","Epoch 2/10\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.8520 - loss: 0.5606 - val_accuracy: 0.9070 - val_loss: 0.3369\n","Epoch 3/10\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.8642 - loss: 0.4260 - val_accuracy: 0.9070 - val_loss: 0.3061\n","Epoch 4/10\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.8380 - loss: 0.4727 - val_accuracy: 0.9070 - val_loss: 0.3128\n","Epoch 5/10\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - accuracy: 0.8657 - loss: 0.4083 - val_accuracy: 0.9070 - val_loss: 0.3217\n","Epoch 6/10\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - accuracy: 0.8720 - loss: 0.3653 - val_accuracy: 0.9070 - val_loss: 0.2850\n","Epoch 7/10\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - accuracy: 0.8451 - loss: 0.4015 - val_accuracy: 0.9070 - val_loss: 0.2334\n","Epoch 8/10\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.8724 - loss: 0.2866 - val_accuracy: 0.9070 - val_loss: 0.1490\n","Epoch 9/10\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9079 - loss: 0.1802 - val_accuracy: 1.0000 - val_loss: 0.1116\n","Epoch 10/10\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.9874 - loss: 0.1286 - val_accuracy: 0.9767 - val_loss: 0.0584\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9741 - loss: 0.0613\n","Test Accuracy: 97.67%\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.99        39\n","           1       0.80      1.00      0.89         4\n","\n","    accuracy                           0.98        43\n","   macro avg       0.90      0.99      0.94        43\n","weighted avg       0.98      0.98      0.98        43\n","\n"]}],"source":["# Import necessary libraries\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Load the dataset\n","dataset_path = \"/content/drive/My Drive/twi.csv\"  # Path in Google Colab\n","\n","data = pd.read_csv(dataset_path)\n","\n","# Separate features (text) and labels (sentiment)\n","texts = data['text'].values\n","labels = data['sentiment'].values\n","\n","# Tokenize and pad sequences\n","vocab_size = 10000  # Vocabulary size for the tokenizer\n","max_length = 50  # Maximum length of each sequence\n","oov_token = \"<OOV>\"  # Out of vocabulary token\n","\n","tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n","tokenizer.fit_on_texts(texts)\n","\n","# Convert texts to sequences and pad them\n","sequences = tokenizer.texts_to_sequences(texts)\n","padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n","\n","# Define the model\n","model = Sequential([\n","    Embedding(vocab_size, 16, input_length=max_length),\n","    Bidirectional(LSTM(64, return_sequences=True)),\n","    Dropout(0.5),\n","    Bidirectional(LSTM(32)),\n","    Dense(64, activation='relu'),\n","    Dropout(0.5),\n","    Dense(1, activation='sigmoid')  # Output layer for binary classification\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","epochs = 10  # Number of epochs\n","batch_size = 32  # Batch size\n","\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=epochs,\n","    batch_size=batch_size,\n","    verbose=1\n",")\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n","print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n","\n","# Generate a classification report\n","y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n","print(classification_report(y_test, y_pred))\n","\n","# Save the model\n","model.save(\"twitter_sentiment_model.h5\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":325,"status":"ok","timestamp":1733996515613,"user":{"displayName":"Erandaka Rusiru","userId":"04457590709685097582"},"user_tz":-330},"id":"xBObUsUYM8uM","outputId":"6158f614-9891-485c-ecac-a6840adc320e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","Sentiment: Happy\n"]}],"source":["# Test with custom text\n","custom_text = [\"fuck you\"]\n","custom_seq = tokenizer.texts_to_sequences(custom_text)\n","custom_padded = pad_sequences(custom_seq, maxlen=max_length, padding='post')\n","custom_prediction = model.predict(custom_padded)\n","\n","if custom_prediction[0][0] > 0.5:\n","    print(\"Sentiment: Happy\")\n","else:\n","    print(\"Sentiment: Sad\")"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOa77R6uEbyVxT7+Zf5ANxs"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}